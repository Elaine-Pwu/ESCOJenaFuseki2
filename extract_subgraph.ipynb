{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2892298a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Extract Skill Subgraph from RDF File\n",
      "======================================================================\n",
      "\n",
      "Input file: data/esco-v1.2.0.rdf\n",
      "Output file: out_esco/skill_subgraph_from_rdf.tsv\n",
      "Skill URI prefix: http://data.europa.eu/esco/skill/\n",
      "\n",
      "======================================================================\n",
      "Step 1: Load RDF File\n",
      "======================================================================\n",
      "Loading RDF file (this may take a few minutes)...\n"
     ]
    }
   ],
   "source": [
    "# Extract Skill Subgraph from RDF File\n",
    "# Extract triples where subject or object is at least one skill from data/esco-v1.2.0.rdf\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from rdflib import Graph\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Extract Skill Subgraph from RDF File\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# File paths\n",
    "rdf_file = \"data/esco-v1.2.0.rdf\"  # RDF/XML format\n",
    "output_dir = Path(\"out_esco\")\n",
    "output_file = output_dir / \"skill_subgraph_from_rdf.tsv\"  # New filename, does not overwrite skill_subgraph_triples.tsv\n",
    "\n",
    "# Skill URI prefix\n",
    "skill_uri_prefix = \"http://data.europa.eu/esco/skill/\"\n",
    "\n",
    "print(f\"\\nInput file: {rdf_file}\")\n",
    "print(f\"Output file: {output_file}\")\n",
    "print(f\"Skill URI prefix: {skill_uri_prefix}\")\n",
    "\n",
    "# Check if input file exists\n",
    "if not Path(rdf_file).exists():\n",
    "    print(f\"\\n⚠️  Error: File {rdf_file} does not exist\")\n",
    "    print(\"  Please ensure the file path is correct\")\n",
    "    raise FileNotFoundError(f\"File not found: {rdf_file}\")\n",
    "\n",
    "# Create output directory\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Step 1: Load RDF File\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Loading RDF file (this may take a few minutes)...\")\n",
    "\n",
    "# Load RDF file\n",
    "graph = Graph()\n",
    "graph.parse(rdf_file, format=\"xml\")\n",
    "\n",
    "print(f\"✓ RDF file loaded successfully\")\n",
    "print(f\"  Total triples: {len(graph):,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Step 2: Extract Subgraph Containing Skills\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Helper function: Convert URI to string uniformly\n",
    "def uri_to_string(uri):\n",
    "    \"\"\"Convert rdflib URI object to string\"\"\"\n",
    "    if isinstance(uri, str):\n",
    "        return uri\n",
    "    elif hasattr(uri, 'toPython'):\n",
    "        return str(uri.toPython())\n",
    "    else:\n",
    "        return str(uri)\n",
    "\n",
    "# Helper function: Check if it's a literal\n",
    "def is_literal(uri_obj):\n",
    "    \"\"\"\n",
    "    Check if it's a literal\n",
    "    In rdflib, Literal objects have a specific type\n",
    "    \"\"\"\n",
    "    from rdflib import Literal\n",
    "    return isinstance(uri_obj, Literal)\n",
    "\n",
    "# Extract all triples containing skills (subject or object is skill)\n",
    "# Only keep URI-to-URI triples (can be directly used for PyKEEN)\n",
    "skill_subgraph_triples = []\n",
    "literal_count = 0\n",
    "\n",
    "print(\"Extracting triples containing Skills (only URI-to-URI, filtering literals)...\")\n",
    "for idx, (subj, pred, obj) in enumerate(graph, 1):\n",
    "    if idx % 100000 == 0:\n",
    "        print(f\"  Processed {idx:,} triples, extracted {len(skill_subgraph_triples):,} relevant triples (filtered {literal_count:,} literals)...\")\n",
    "    \n",
    "    # Check if object is a literal (if so, skip this triple)\n",
    "    if is_literal(obj):\n",
    "        literal_count += 1\n",
    "        continue\n",
    "    \n",
    "    # Convert to string uniformly\n",
    "    subj_str = uri_to_string(subj)\n",
    "    pred_str = uri_to_string(pred)\n",
    "    obj_str = uri_to_string(obj)\n",
    "    \n",
    "    # Check if subject or object is a skill\n",
    "    is_subj_skill = subj_str.startswith(skill_uri_prefix)\n",
    "    is_obj_skill = obj_str.startswith(skill_uri_prefix)\n",
    "    \n",
    "    # If subject or object is a skill, keep this triple\n",
    "    if is_subj_skill or is_obj_skill:\n",
    "        skill_subgraph_triples.append([subj_str, pred_str, obj_str])\n",
    "\n",
    "print(f\"\\n✓ Extracted {len(skill_subgraph_triples):,} triples containing Skills (URI-to-URI, can be directly used for PyKEEN)\")\n",
    "print(f\"  Original triples: {len(graph):,}\")\n",
    "print(f\"  Subgraph triples: {len(skill_subgraph_triples):,}\")\n",
    "print(f\"  Filtered literal triples: {literal_count:,}\")\n",
    "if len(graph) > 0:\n",
    "    print(f\"  Retention ratio: {len(skill_subgraph_triples)/len(graph)*100:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Step 3: Save Subgraph to TSV File\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save as TSV format\n",
    "subgraph_df = pd.DataFrame(skill_subgraph_triples, columns=['subject', 'predicate', 'object'])\n",
    "subgraph_df.to_csv(output_file, sep='\\t', index=False, header=False, encoding='utf-8')\n",
    "\n",
    "print(f\"✓ Subgraph saved to: {output_file}\")\n",
    "print(f\"  File size: {Path(output_file).stat().st_size / (1024**2):.2f} MB\")\n",
    "print(f\"  Number of rows: {len(subgraph_df):,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Extraction Complete!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nExtraction Principle:\")\n",
    "print(f\"  1. Read all triples from RDF/XML file\")\n",
    "print(f\"  2. Identify all Skill URIs (by prefix matching: {skill_uri_prefix})\")\n",
    "print(f\"  3. Filter out triples containing literals, only keep URI-to-URI triples\")\n",
    "print(f\"  4. Keep all triples containing Skills (subject or object is Skill)\")\n",
    "print(f\"  5. Save as TSV format for subsequent use\")\n",
    "print(f\"\\nThe extracted subgraph contains:\")\n",
    "print(f\"  - All Skill entities\")\n",
    "print(f\"  - Relationships between Skills (e.g., broader/narrower)\")\n",
    "print(f\"  - Associations between Skills and other entities (e.g., occupation, concept, etc.)\")\n",
    "print(f\"  - Does not contain literals (e.g., label, description and other text attributes)\")\n",
    "print(f\"\\n✓ All triples are URI-to-URI and can be directly used for PyKEEN training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085f4e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "检查三元组中的重复项\n",
      "======================================================================\n",
      "\n",
      "检查文件: out_esco/skill_subgraph_from_rdf.tsv\n",
      "\n",
      "正在加载文件...\n",
      "✓ 加载完成: 1,816,462 行\n",
      "\n",
      "======================================================================\n",
      "检查重复项\n",
      "======================================================================\n",
      "\n",
      "1. 检查完全重复的三元组...\n",
      "  总行数: 1,816,462\n",
      "  唯一三元组数: 1,816,462\n",
      "  重复行数: 0\n",
      "  ✓ 没有发现完全重复的三元组\n",
      "\n",
      "======================================================================\n",
      "2. 检查 (subject, predicate) 对的重复情况\n",
      "======================================================================\n",
      "  发现 127,515 个 (subject, predicate) 对有多个不同的 object\n",
      "  这是正常的（一个实体可以通过同一个关系关联到多个实体）\n",
      "\n",
      "  示例（前5个）:\n",
      "\n",
      "    Subject: http://data.europa.eu/esco/concept-scheme/6c930acd-c104-4ece...\n",
      "    Predicate: http://www.w3.org/2004/02/skos/core#hasTopConcept...\n",
      "    有 1158 个不同的 object:\n",
      "      1. http://data.europa.eu/esco/skill/3703eac1-8941-4d14-b305-b03...\n",
      "      2. http://data.europa.eu/esco/skill/20c6a2ec-ef98-4f95-8a16-c80...\n",
      "      3. http://data.europa.eu/esco/skill/60f2ec1a-9237-4d0e-8c4a-1a3...\n",
      "      ... 还有 1155 个\n",
      "\n",
      "    Subject: http://data.europa.eu/esco/concept-scheme/digcomp...\n",
      "    Predicate: http://www.w3.org/2004/02/skos/core#hasTopConcept...\n",
      "    有 5 个不同的 object:\n",
      "      1. http://data.europa.eu/esco/skill/574257ea-7b64-4100-b7b6-e27...\n",
      "      2. http://data.europa.eu/esco/skill/f5369f2f-e52b-43d8-8d31-79a...\n",
      "      3. http://data.europa.eu/esco/skill/7e5147d1-60b1-4a68-804b-1f5...\n",
      "      ... 还有 2 个\n",
      "\n",
      "    Subject: http://data.europa.eu/esco/concept-scheme/green...\n",
      "    Predicate: http://www.w3.org/2004/02/skos/core#hasTopConcept...\n",
      "    有 512 个不同的 object:\n",
      "      1. http://data.europa.eu/esco/skill/1b73b2a7-aefc-49ef-8b30-b90...\n",
      "      2. http://data.europa.eu/esco/skill/e979659d-d06e-4968-b4b2-ac5...\n",
      "      3. http://data.europa.eu/esco/skill/46454506-fb7c-4ad7-84e0-d4a...\n",
      "      ... 还有 509 个\n",
      "\n",
      "    Subject: http://data.europa.eu/esco/concept-scheme/member-skills...\n",
      "    Predicate: http://www.w3.org/2004/02/skos/core#hasTopConcept...\n",
      "    有 9175 个不同的 object:\n",
      "      1. http://data.europa.eu/esco/skill/655d3d08-680a-40ea-8ffd-7e6...\n",
      "      2. http://data.europa.eu/esco/skill/29e20150-b7f0-46ef-8175-ff6...\n",
      "      3. http://data.europa.eu/esco/skill/8a2f841c-fe35-46c0-90bd-518...\n",
      "      ... 还有 9172 个\n",
      "\n",
      "    Subject: http://data.europa.eu/esco/concept-scheme/research...\n",
      "    Predicate: http://www.w3.org/2004/02/skos/core#hasTopConcept...\n",
      "    有 39 个不同的 object:\n",
      "      1. http://data.europa.eu/esco/skill/872a1632-f1db-4feb-bb27-0a6...\n",
      "      2. http://data.europa.eu/esco/skill/5f0082ab-2131-49b5-94d6-a18...\n",
      "      3. http://data.europa.eu/esco/skill/a8d24a95-47b3-4f88-92e7-066...\n",
      "      ... 还有 36 个\n",
      "\n",
      "======================================================================\n",
      "3. 检查 (subject, object) 对的重复情况\n",
      "======================================================================\n",
      "  发现 31,781 个 (subject, object) 对有多个不同的 predicate\n",
      "  这是正常的（两个实体之间可以有多种关系）\n",
      "\n",
      "  示例（前5个）:\n",
      "\n",
      "    Subject: http://data.europa.eu/esco/isced-f/00...\n",
      "    Object: http://data.europa.eu/esco/skill/c46fcb45-5c14-4ffa-abed-5a4...\n",
      "    有 2 个不同的 predicate:\n",
      "      1. http://www.w3.org/2004/02/skos/core#broader...\n",
      "      2. http://www.w3.org/2004/02/skos/core#broaderTransitive...\n",
      "\n",
      "    Subject: http://data.europa.eu/esco/isced-f/01...\n",
      "    Object: http://data.europa.eu/esco/skill/c46fcb45-5c14-4ffa-abed-5a4...\n",
      "    有 2 个不同的 predicate:\n",
      "      1. http://www.w3.org/2004/02/skos/core#broaderTransitive...\n",
      "      2. http://www.w3.org/2004/02/skos/core#broader...\n",
      "\n",
      "    Subject: http://data.europa.eu/esco/isced-f/02...\n",
      "    Object: http://data.europa.eu/esco/skill/c46fcb45-5c14-4ffa-abed-5a4...\n",
      "    有 2 个不同的 predicate:\n",
      "      1. http://www.w3.org/2004/02/skos/core#broaderTransitive...\n",
      "      2. http://www.w3.org/2004/02/skos/core#broader...\n",
      "\n",
      "    Subject: http://data.europa.eu/esco/isced-f/03...\n",
      "    Object: http://data.europa.eu/esco/skill/c46fcb45-5c14-4ffa-abed-5a4...\n",
      "    有 2 个不同的 predicate:\n",
      "      1. http://www.w3.org/2004/02/skos/core#broader...\n",
      "      2. http://www.w3.org/2004/02/skos/core#broaderTransitive...\n",
      "\n",
      "    Subject: http://data.europa.eu/esco/isced-f/04...\n",
      "    Object: http://data.europa.eu/esco/skill/c46fcb45-5c14-4ffa-abed-5a4...\n",
      "    有 2 个不同的 predicate:\n",
      "      1. http://www.w3.org/2004/02/skos/core#broader...\n",
      "      2. http://www.w3.org/2004/02/skos/core#broaderTransitive...\n",
      "\n",
      "======================================================================\n",
      "检查完成\n",
      "======================================================================\n",
      "\n",
      "✓ 没有发现完全重复的三元组，数据质量良好\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in extracted triples\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Check for Duplicates in Triples\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# File path\n",
    "tsv_file = \"out_esco/skill_subgraph_from_rdf.tsv\"\n",
    "\n",
    "print(f\"\\nChecking file: {tsv_file}\")\n",
    "\n",
    "# Load file\n",
    "print(\"\\nLoading file...\")\n",
    "df = pd.read_csv(\n",
    "    tsv_file,\n",
    "    sep='\\t',\n",
    "    header=None,\n",
    "    names=['subject', 'predicate', 'object'],\n",
    "    encoding='utf-8'\n",
    ")\n",
    "print(f\"✓ Loaded successfully: {len(df):,} rows\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Checking for Duplicates\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check for completely duplicate triples (subject, predicate, object are identical)\n",
    "print(\"\\n1. Checking for completely duplicate triples...\")\n",
    "duplicated_rows = df.duplicated(keep=False)  # keep=False marks all duplicates (including first occurrence)\n",
    "num_duplicated = duplicated_rows.sum()\n",
    "num_unique = df.drop_duplicates().shape[0]\n",
    "\n",
    "print(f\"  Total rows: {len(df):,}\")\n",
    "print(f\"  Unique triples: {num_unique:,}\")\n",
    "print(f\"  Duplicate rows: {num_duplicated:,}\")\n",
    "\n",
    "if num_duplicated > 0:\n",
    "    print(f\"  ⚠️  Found {num_duplicated:,} duplicate rows\")\n",
    "    print(f\"  Duplicate ratio: {num_duplicated/len(df)*100:.2f}%\")\n",
    "    \n",
    "    # Display statistics of duplicates\n",
    "    duplicated_df = df[duplicated_rows]\n",
    "    duplicate_counts = duplicated_df.groupby(['subject', 'predicate', 'object']).size().reset_index(name='count')\n",
    "    duplicate_counts = duplicate_counts[duplicate_counts['count'] > 1].sort_values('count', ascending=False)\n",
    "    \n",
    "    print(f\"\\n  Duplicate triple details:\")\n",
    "    print(f\"    {len(duplicate_counts):,} different triples appear multiple times\")\n",
    "    print(f\"    Maximum duplicate count: {duplicate_counts['count'].max()}\")\n",
    "    print(f\"    Average duplicate count: {duplicate_counts['count'].mean():.2f}\")\n",
    "    \n",
    "    # Display top 10 most duplicated triples\n",
    "    print(f\"\\n  Top 10 most duplicated triples:\")\n",
    "    for idx, row in duplicate_counts.head(10).iterrows():\n",
    "        print(f\"\\n    {idx+1}. Duplicated {int(row['count'])} times:\")\n",
    "        print(f\"       Subject: {row['subject'][:80]}...\")\n",
    "        print(f\"       Predicate: {row['predicate'][:80]}...\")\n",
    "        print(f\"       Object: {row['object'][:80]}...\")\n",
    "else:\n",
    "    print(f\"  ✓ No completely duplicate triples found\")\n",
    "\n",
    "# Check for duplicate (subject, predicate) pairs (different objects)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"2. Checking (subject, predicate) pair duplicates\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "subject_predicate_duplicates = df.groupby(['subject', 'predicate']).size()\n",
    "multiple_objects = subject_predicate_duplicates[subject_predicate_duplicates > 1]\n",
    "\n",
    "if len(multiple_objects) > 0:\n",
    "    print(f\"  Found {len(multiple_objects):,} (subject, predicate) pairs with multiple different objects\")\n",
    "    print(f\"  This is normal (one entity can be related to multiple entities through the same relation)\")\n",
    "    print(f\"\\n  Examples (top 5):\")\n",
    "    for (subj, pred), count in multiple_objects.head(5).items():\n",
    "        print(f\"\\n    Subject: {subj[:60]}...\")\n",
    "        print(f\"    Predicate: {pred[:60]}...\")\n",
    "        print(f\"    Has {count} different objects:\")\n",
    "        objects = df[(df['subject'] == subj) & (df['predicate'] == pred)]['object'].unique()\n",
    "        for i, obj in enumerate(objects[:3], 1):  # Only show first 3\n",
    "            print(f\"      {i}. {obj[:60]}...\")\n",
    "        if len(objects) > 3:\n",
    "            print(f\"      ... and {len(objects) - 3} more\")\n",
    "else:\n",
    "    print(f\"  ✓ No (subject, predicate) pair duplicates found\")\n",
    "\n",
    "# Check for duplicate (subject, object) pairs (different predicates)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"3. Checking (subject, object) pair duplicates\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "subject_object_duplicates = df.groupby(['subject', 'object']).size()\n",
    "multiple_predicates = subject_object_duplicates[subject_object_duplicates > 1]\n",
    "\n",
    "if len(multiple_predicates) > 0:\n",
    "    print(f\"  Found {len(multiple_predicates):,} (subject, object) pairs with multiple different predicates\")\n",
    "    print(f\"  This is normal (two entities can have multiple relationships)\")\n",
    "    print(f\"\\n  Examples (top 5):\")\n",
    "    for (subj, obj), count in multiple_predicates.head(5).items():\n",
    "        print(f\"\\n    Subject: {subj[:60]}...\")\n",
    "        print(f\"    Object: {obj[:60]}...\")\n",
    "        print(f\"    Has {count} different predicates:\")\n",
    "        predicates = df[(df['subject'] == subj) & (df['object'] == obj)]['predicate'].unique()\n",
    "        for i, pred in enumerate(predicates, 1):\n",
    "            print(f\"      {i}. {pred[:60]}...\")\n",
    "else:\n",
    "    print(f\"  ✓ No (subject, object) pair duplicates found\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Check Complete\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if num_duplicated > 0:\n",
    "    print(f\"\\n⚠️  Found {num_duplicated:,} completely duplicate triples\")\n",
    "    print(f\"  Suggestion: If deduplication is needed, use df.drop_duplicates()\")\n",
    "else:\n",
    "    print(f\"\\n✓ No completely duplicate triples found, data quality is good\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f98130",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
